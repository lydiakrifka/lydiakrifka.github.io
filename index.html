<!doctype html>
<html lang="en" class="scroll-smooth">
<head>
    <meta charset="UTF-8" />
    <link rel="icon" type="image/svg+xml" href="./src/favicon.svg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Lydia Krifka-Dobes</title>
    <script type="module" src="/src/main.ts"></script>
</head>
<body>
    <main class="font-serif text-2xl/8 md:text-4xl/13">
        <div class="relative w-full h-screen flex items-center">
            <img class="absolute w-full h-full object-cover" src="./src/images/_DSC6046.JPG" srcset="
            ./src/images/_DSC6046.JPG 1024w,
            ./src/images/_DSC6046.JPG 1920w
          " sizes="50vw" alt="Lydia Krifka-Dobes" />
            <h1 class="text-white italic relative z-10 px-4 md:px-8 py-5 font-swash antialiased text-5xl md:text-7xl">
                Lydia Krifka-Dobes
            </h1>
        </div>
        <div class="p-4 md:p-8">
            <div class="[&_a]:hover:italic">
                <div class="space-y-4 md:space-y-6 pb-10 mb-10 border-b-10 border-red">
                    <p>
                         Lydia is a researcher, sound artist and computer musician who actively investigates the
                        alternative creativity of computational intelligence in sound. Through autonomous musical
                        systems that interact and improvise with human collaborators in multichannel contexts, she
                        explores how human and machine perceptions diverge, shaping distinct artistic interpretations
                        and
                        decisions. Her ongoing research is taking place in Sound & Music Computation at Music Technology
                        Group Barcelona where she
                        works on Systems & Multimedia architect with C++ / Vulkan / DSP / Concurrency.
                    </p>
                    <p>
                        Her current artistic interests are centered around computer music and noise, through algorithmic
                        composition, live coding, and sound installation, exploring musicality in noise within the
                        concepts of music, information, and systems.
                    </p>
                </div>
            </div>
            
            <!-- EDUCATION SECTION -->
            <div class="pb-10 mb-10 border-b-10 border-red">
                <h2 class="mb-20 italic">Education</h2>
                <div class="[&_a]:hover:italic space-y-8">
                    <div>
                        <p class="font-bold">Universitat Pompeu Fabra (UPF), Barcelona, Spain</p>
                        <p>M.Eng. Sound and Music Computing | 2025–2026</p>
                        <p class="mt-3">Music Technology Group with Prof. Xavier Serra</p>
                        <p class="mt-3"><strong>Coursework:</strong></p>
                        <ul class="list-disc pl-8 space-y-2">
                            <li>Music Generation with Neural Networks</li>
                            <li>Machine Learning for Audio</li>
                            <li>Music Information Retrieval</li>
                        </ul>
                    </div>
                    <div>
                        <p class="font-bold">Institute of Sonology, The Hague, Netherlands</p>
                        <p>B.Mus., Sonology (Computer Music) | 2020-2025</p>
                        <p class="mt-3"><strong>Key Courses:</strong></p>
                        <ul class="list-disc pl-8 space-y-2">
                            <li>Signal Processing - Analysis & Resynthesis, Physical Modeling, Convolution, Transformation algorithms</li>
                            <li>Musical Controllers - Analog electronics, controller & interface design, sensor data extraction and manipulation</li>
                            <li>Sound and Space - WaveField Synthesis, cultural and philosophical theories of space</li>
                        </ul>
                        <p class="mt-3"><strong>Research:</strong> Interdisciplinary contextualization of electronic music: Study of interactive media improvisation, developing C++ libraries for gesture tracking and synthesis algorithms</p>
                        <p class="mt-3"><strong>Bachelor's Thesis:</strong> Wandering the Sounds of Languages (2025)</p>
                    </div>
                    <div>
                        <p class="font-bold">Conservatory Olomouc, Olomouc, Czechia</p>
                        <p>B.A. (Honours) Music and Sound | 2014–2017</p>
                        <p class="mt-3">Sound Spatialization Research (thesis), Sound Engineering, Studio techniques, Mixing & Mastering, Composition for moving image, Library music, Gregorian Chant, Violin performance</p>
                    </div>
                </div>
            </div>

            <!-- EXPERIENCE SECTION -->
            <div class="pb-10 mb-10 border-b-10 border-red">
                <h2 class="mb-20 italic">Experience</h2>
                <div class="[&_a]:hover:italic space-y-8">
                    <div>
                        <p class="font-bold">La Biennale di Venezia Musica, Selected Artist</p>
                        <p>Venice, Italy | 2023</p>
                        <p class="mt-3"><em>Wandering the Piano:</em> 16-channel ambisonic installation</p>
                        <ul class="list-disc pl-8 space-y-2 mt-3">
                            <li>Exploring piano mechanics through 64 infrared sensors and K-means clustering of 10,000 piano samples</li>
                            <li>Premiered under curator Lucia Ronchetti</li>
                            <li>Supervision: Miller Puckette, Gerfried Stocker (Ars Electronica)</li>
                        </ul>
                    </div>
                    <div>
                        <p class="font-bold">Leibniz-Centre General Linguistics, Berlin, Germany</p>
                        <p>Research Intern with Prof. Dr. Marzena Żygis | 2023–2025</p>
                        <ul class="list-disc pl-8 space-y-2 mt-3">
                            <li>Contributed to ATTIT project on implicit and explicit attitudes toward foreign language accents in German-Polish contexts</li>
                            <li>Analyzed whispered speech acoustics and facial expressions using spectral analysis</li>
                            <li>Developed multi-threaded real-time processing pipeline using C++ and OpenCV for facial movement analysis</li>
                        </ul>
                    </div>
                    <div>
                        <p class="font-bold">Max Planck Institute for Human Development, Berlin, Germany</p>
                        <p>Research Assistant with Prof. Dr. Gerd Gigerenzer | 2018</p>
                        <ul class="list-disc pl-8 space-y-2 mt-3">
                            <li>Built sonification and data visualization pipelines for risk education for the public</li>
                            <li>Developed statistical analysis tools using openFrameworks for interactive data exploration of false positives</li>
                            <li>Edited campaign project for high school statistics education</li>
                        </ul>
                    </div>
                    <div>
                        <p class="font-bold">Vertigo Games, Rotterdam, Netherlands</p>
                        <p>Audio Intern | 2024</p>
                        <ul class="list-disc pl-8 space-y-2 mt-3">
                            <li>Hands-on experience with VR, collision SFX, locomotion SFX</li>
                            <li>Audio implementation using Unreal Engine</li>
                        </ul>
                    </div>
                    <div>
                        <p class="font-bold">Ableton, Berlin, Germany</p>
                        <p>Marketing Intern | 2018</p>
                        <ul class="list-disc pl-8 space-y-2 mt-3">
                            <li>Created interactive audiovisual media content for marketing and outreach team</li>
                            <li>Using Blender and layering of short microsounds from recording sessions with DJs</li>
                        </ul>
                    </div>
                </div>
            </div>

            <!-- PROGRAMMING SECTION -->
            <div class="pb-10 mb-10 border-b-10 border-lavender">
                <h2 class="mb-20 italic">Programming & Technical Work</h2>
                <div class="[&_a]:hover:italic space-y-8">
                    <div>
                        <p class="font-bold">Gesture Tracking Library</p>
                        <ul class="list-disc pl-8 space-y-2">
                            <li>Writing libraries in C++ to recognize and manipulate artistic gestures</li>
                            <li>Working with gesture controllers such as Kinect, LeapMotion and Sketch tablet</li>
                            <li>Used Kernel convolution (OpenCV) to detect edges, corners, defined features and optical flow</li>
                            <li>Algorithms to translate data into different domains (sound to animation)</li>
                        </ul>
                    </div>
                    <div>
                        <p class="font-bold">Audio Analysis</p>
                        <ul class="list-disc pl-8 space-y-2">
                            <li>Detect audio features: Frequency centroids, busyness, silences</li>
                            <li>Spectral components: formants, melodic spectrum, Vowel extraction and Fourier resynthesis</li>
                            <li>Merging features from different audio files into one</li>
                            <li>Wave shaping using custom dynamic-stochastic-synthesis</li>
                        </ul>
                    </div>
                    <div>
                        <p class="font-bold">Open Source Contributions</p>
                        <ul class="list-disc pl-8 space-y-2">
                            <li>PRs to Neovim plugins</li>
                            <li>PRs to Tree Sitter</li>
                            <li>Bug tracking in AURs</li>
                            <li>PD Externals</li>
                            <li>OpenFrameworks addons for working with Threaded Features</li>
                        </ul>
                    </div>
                </div>
            </div>

            <!-- TEACHING & WORKSHOPS SECTION -->
            <div class="pb-10 mb-10 border-b-10 border-blue">
                <h2 class="mb-20 italic">Teaching & Workshops</h2>
                <div class="[&_a]:hover:italic space-y-8">
                    <div>
                        <p class="font-bold">Curiosity Club Barcelona, Spain</p>
                        <p>Workshop, Sound & Space Workshop Series | 2025</p>
                        <ul class="list-disc pl-8 space-y-2 mt-3">
                            <li>Intensive spatial audio training including acousmatrix, soundspace theory, microphone techniques</li>
                            <li>My experience working with analog synthesizers, extended range violin, electroacoustic ensembles</li>
                        </ul>
                    </div>
                    <div>
                        <p class="font-bold">Jugend Hackt, Berlin, Germany</p>
                        <p>Youth Technology Mentor | 2018–present</p>
                        <ul class="list-disc pl-8 space-y-2 mt-3">
                            <li>Mentoring young technologists (ages 12-18) in creative coding, electronics, sound design</li>
                            <li>Workshop topics: Arduino, live coding, real-time video AI, generative art</li>
                            <li>Organized a generative art hackathon: first underground youth hackathon in Berlin with 365 signups, 80 mentorship submissions</li>
                            <li>Led Real-time Video AI/AR Workshop: monthly workshops on Generative AI live streaming platform</li>
                            <li>Mentored Twinthesizer workshop: real-time tweet sentiment sonification</li>
                        </ul>
                    </div>
                    <div>
                        <p class="font-bold">Deutsche Oper Berlin, Berlin, Germany</p>
                        <p>Workshop Supervisor, Common Sound Minifestival | 2019</p>
                        <ul class="list-disc pl-8 space-y-2 mt-3">
                            <li>Micro-festival for 15+ young artists; Production Assistant</li>
                            <li>Helped curate 1-week residency exploring transcultural performance and hybrid opera forms</li>
                            <li>Parametric Point Cloud Modeling with LeapMotion for performance</li>
                        </ul>
                    </div>
                    <div>
                        <p class="font-bold">Private Teaching, Various Locations</p>
                        <p>Music Educator | 2011–present</p>
                        <ul class="list-disc pl-8 space-y-2 mt-3">
                            <li>Teaching improvisation to preschool and primary school students (2014–2017)</li>
                            <li>Private violin instruction (2011–present)</li>
                        </ul>
                    </div>
                </div>
            </div>

            <!-- AWARDS & RECOGNITION SECTION -->
            <div class="pb-10 mb-10 border-b-10 border-blue">
                <h2 class="mb-20 italic">Awards & Recognition</h2>
                <div class="[&_a]:hover:italic space-y-4">
                    <p>Audio Developer Conference Diversity Scholarship, Bristol, UK | 2025</p>
                    <p>Excellence Scholarship (€15,000), The Hague, NL | 2022</p>
                    <p>First Prize, German National Composition Competition, Berlin, DE | 2021</p>
                    <p>First Prize, Bundeswettbewerb Jugend Komponiert, Schloss Weikersheim, DE</p>
                    <p>Scholarship, School for Poetic Computation (Workshop: CW&T), NYC/online | 2019</p>
                    <p>MIT Media Lab's Hackathon Arts Participant, Cambridge, MA | 2019</p>
                    <p>First Prize, Jugend Hackt Hackathon, Berlin, DE | 2018</p>
                    <p>Regional Winner, Jugend forscht Research Competition, Berlin, DE | 2018</p>
                    <p>WWDC Scholarship Recipient, Cupertino, CA | 2016</p>
                </div>
            </div>

            <!-- VOLUNTEER SECTION -->
            <div class="pb-10 mb-10 border-b-10 border-blue">
                <h2 class="mb-20 italic">Volunteer Work</h2>
                <div class="[&_a]:hover:italic space-y-4">
                    <p>
                        <strong>Conference on the Future of Europe</strong><br />
                        Citizen Panelist | Strasbourg, Florence, Brussels | 2021–2022<br />
                        Participated in EU-wide debates on climate policy; successfully proposed law changes including taxing negative externalities of agricultural activity (proposal 30.2)
                    </p>
                    <p>
                        <strong>World Servants</strong><br />
                        Volunteer | Malawi, Germany, Netherlands | 2017–2018<br />
                        Orchestrated benefit dinners and fundraising initiatives raising €150,000 collectively for primary school infrastructure in Makonje, Malawi
                    </p>
                </div>
            </div>

            <!-- SELECTED ARTSCIENCE PROJECTS -->
            <div class="pb-10 mb-10 border-b-10 border-red">
                <h2 class="mb-20 italic">Selected ArtScience Projects</h2>
                <div class="[&_a]:hover:italic space-y-10">
                    
                    <!-- WANDERING THE PIANO -->
                    <section>
                        <h4 class="font-bold mb-2">WANDERING THE PIANO</h4>
                        <p class="mb-3">
                            <strong>La Biennale di Venezia Musica (IT)</strong><br />
                            Sound installation / Multichannel spatial performance (16-channel) | 2023
                        </p>
                        <p class="mb-3">
                            In 2023 (JAN-OCT), I was selected as the youngest artist of the festival (Biennale Musica sector). Along with nine other composers, performers, and musicians, I was awarded an artistic residency to produce my installation <em>Wandering the Piano</em>, which premiered at the Biennale Musica di Venezia 2023 under the curation of Lucia Ronchetti and under supervision of Prof. Dr. Miller Smith Puckette, Prof. Dr Gerfried Stocker (Ars Electronica), and Ali Nikrang (Ars Electronica, Future Lab).
                        </p>
                        <p class="mb-3">
                            The installation explored the spatial and mechanical memory of the piano through fragmented motifs, prepared strings, and resonant responses to movement, creating a dialogue between performer and instrument.
                        </p>
                        <p class="mb-3">
                            There are (2) main components of this installation:
                        </p>
                        <ul class="list-disc pl-8 mb-3">
                            <li>Creation and curation of a large dataset of >10,000 sound files</li>
                            <li>Creation of 8 spatial maps (soundscapes) with 64 sounds each</li>
                        </ul>
                        <p class="mb-3">
                            YouTube: Amateur film:<br />
                            <a href="https://www.youtube.com/watch?v=dts4YQDgXVw" target="_blank" rel="noopener noreferrer" class="text-blue font-bold shadow-lg">
                                https://www.youtube.com/watch?v=dts4YQDgXVw
                            </a>
                        </p>
                        <p class="mb-3">
                            La Biennale Website:<br />
                            <a href="https://www.labiennale.org/en/music/2023/music-performances/lydia-krifka-dobes-wandering-piano" target="_blank" rel="noopener noreferrer" class="text-blue font-bold shadow-lg">
                                https://www.labiennale.org/en/music/2023/music-performances/lydia-krifka-dobes-wandering-piano
                            </a>
                        </p>
                        <p class="mb-3">
                            Version 1 Code:<br />
                            <a href="https://drive.google.com/file/d/1ZiyisKzEQCcyZq-QzN87tD2KZLJCkB4w/view?usp=sharing" target="_blank" rel="noopener noreferrer" class="text-blue font-bold shadow-lg">
                                https://drive.google.com/file/d/1ZiyisKzEQCcyZq-QzN87tD2KZLJCkB4w/view?usp=sharing
                            </a>
                        </p>
                    </section>

                    <!-- 01001100.mov -->
                    <section>
                        <h4 class="font-bold mb-2">01001100.mov (DE)</h4>
                        <p class="mb-3">
                            Composition for choreography (Extended-range violin + dance) | 12′15 | 2022–2023
                        </p>
                        <p class="mb-3">
                            In 2022 & 2023 I collaborated with contemporary dancer and choreographer Adithi. The work focuses on exploring everyday gestures, both the extent and the emotions evoked by them. Music for the piece is parallel in places to the dance and accompanying in certain places. Music for this piece is composed on extended range violin, freeze pedal and convolution. Constantly varying tempos, artificial harmonics overlapped by microtones, unsync counterpoint, and multi-phonics are some of the concepts used for sound. Dance explores gestures not just as artistic elements but to query the cultural space and its practices.
                        </p>
                        <p class="mb-3">
                            Watch:<br />
                            <a href="https://drive.google.com/file/d/1x_MiH9oyBDrd1CgKFSBVRZ6jyVJOHbrN/view?usp=sharing" target="_blank" rel="noopener noreferrer" class="text-blue font-bold shadow-lg">
                                https://drive.google.com/file/d/1x_MiH9oyBDrd1CgKFSBVRZ6jyVJOHbrN/view?usp=sharing
                            </a>
                        </p>
                    </section>

                    <!-- WANDERING THE SOUNDS OF LANGUAGES -->
                    <section>
                        <h4 class="font-bold mb-2">WANDERING THE SOUNDS OF LANGUAGES (NL)</h4>
                        <p class="mb-3">
                            Interactive sound/language installation + Website interface / research concert | 17′00 (looped installation) | 2025
                        </p>
                        <p class="mb-3">
                            There are two main components to this research: (1) Curation and analysis of recordings of Aesop's fable in 22 highly diverse languages and (2) Collective retelling of the story for an installation or a website on utterance level.
                        </p>
                        <p class="mb-3">
                            Drawing from my experience with different languages, from growing up trilingual to encountering the languages of Vanuatu, I explore ways to appreciate the variety of spoken languages in their acoustic realization. I work with recordings of the same text, a fable by Aesop, which appeals to many cultures and carries great significance in the face of language endangerment.
                        </p>
                        <p class="mb-3">
                            A concert-research presentation expanding on my thesis project, combining field recordings of Aesop's Fable across 22 languages with live phonetic sonification. Audience members interacted with an interface displaying parallel speech gestures as spatial sound fields.
                        </p>
                        <p class="mb-3">
                            Presentation at Sonology for documentation:<br />
                            <a href="https://drive.google.com/file/d/1fa5kiLGAkGCzdIe28EKIosv3bViizRPG/view?usp=sharing" target="_blank" rel="noopener noreferrer" class="text-blue font-bold shadow-lg">
                                https://drive.google.com/file/d/1fa5kiLGAkGCzdIe28EKIosv3bViizRPG/view?usp=sharing
                            </a>
                        </p>
                        <p class="mb-3">
                            Bachelors language research - Sounds of Languages Thesis (2025, Institute of Sonology):<br />
                            <a href="https://drive.google.com/drive/folders/1joZ3wgK0aZhOOPxlf1VOXy2Jzwor2NzW?usp=sharing" target="_blank" rel="noopener noreferrer" class="text-blue font-bold shadow-lg">
                                https://drive.google.com/drive/folders/1joZ3wgK0aZhOOPxlf1VOXy2Jzwor2NzW?usp=sharing
                            </a>
                        </p>
                    </section>

                    <!-- GAME OF LIFE :: QUICKSEND -->
                    <section>
                        <h4 class="font-bold mb-2">GAME OF LIFE :: QUICKSEND (NL)</h4>
                        <p class="mb-3">
                            192-channel (Wave Field Synthesis System) live coding | 2023
                        </p>
                        <p class="mb-3">
                            Quicksend is a live-coded performance presented in the Wave Field Synthesis (WFS) system by Game of Life Foundation. The system consists of 192 loudspeakers to create an immersive virtual acoustic environment. Quicksend utilises an audio feedback algorithm in search of the border between noise and tone.
                        </p>
                    </section>

                    <!-- GAME OF LIFE :: ZUNGENTANZ -->
                    <section>
                        <h4 class="font-bold mb-2">GAME OF LIFE :: ZUNGENTANZ (NL)</h4>
                        <p class="mb-3">
                            192-channel (Wave Field Synthesis System) fixed media | 6′ | 2025
                        </p>
                        <p class="mb-3">
                            Showcased at the Game of Life Festival as part of the Institute of Sonology's featured presentations. Zungentanz (6′): The three main components of this Fixed Media piece: Spatial mapping of vowel positions to physical coordinates using Wave Field Synthesis, extending micro-choreographies of speech articulation and the mechanics of resonant acoustic memory within the oral cavity.
                        </p>
                        <p class="mb-3">
                            The idea of this project is to virtually place the listener inside the oral cavity of a speaker to appreciate the complexity of movement while we speak. In particular, I observe the vowels in the so-called vowel quadrant that identifies the position of the tongue (e.g. i: high, front, u: high, back, a: low, central) and map them to virtual points in space using Wave Field Analysis.
                        </p>
                        <p class="mb-3">
                            Game of Life Festival:<br />
                            <a href="https://www.koncon.nl/en/events/wave-field-synthesis-festival-2" target="_blank" rel="noopener noreferrer" class="text-blue font-bold shadow-lg">
                                https://www.koncon.nl/en/events/wave-field-synthesis-festival-2
                            </a>
                        </p>
                    </section>

                    <!-- DOOM SCROLLING -->
                    <section>
                        <h4 class="font-bold mb-2">DOOM SCROLLING</h4>
                        <p class="mb-3">
                            AI-driven performance exploring algorithmic identity through real-time Instagram Reels sampling | 2023
                        </p>
                    </section>

                    <!-- UNERHÖRT UNDERGROUND PERFORMANCE -->
                    <section>
                        <h4 class="font-bold mb-2">UNERHÖRT UNDERGROUND PERFORMANCE</h4>
                        <p class="mb-3">
                            Cellular automata-based autonomous musical system with Butoh dancers | 2025
                        </p>
                    </section>

                    <!-- MOTHER TONGUES -->
                    <section>
                        <h4 class="font-bold mb-2">MOTHER TONGUES</h4>
                        <p class="mb-3">
                            Generative visualization of language extinction through genetic algorithms | 2023
                        </p>
                    </section>

                    <!-- CONTOUR & FEATURE TRACKER -->
                    <section>
                        <h4 class="font-bold mb-2">CONTOUR & FEATURE TRACKER</h4>
                        <p class="mb-3">
                            Real-time computer vision code for performance (openFrameworks / C++) | Ongoing | 2024+
                        </p>
                        <p class="mb-3">
                            This is a reference implementation of my ongoing work with openCV API. Once complete it will be released both as a standalone library and openFrameworks add-on. I am using the contour-finder algorithm (using kernel convolution techniques such as Sobel + Canny edge-detection, etc.) to recognize contours from a moving image. Using Shi-Tomasi Algorithm to define and extract features that can be selectively synthesized to form newer shapes or animated to form distortions within the contours. All processing is done parallelly using POCO thread library.
                        </p>
                        <p class="mb-3">
                            The library has enhanced corner detection algorithms, expanded by me, that will directly contribute to my research at Long Meadow Art Residency. It will help understand the relationship between a movement artist and latent inanimate objects in the space.
                        </p>
                        <p class="mb-3">
                            Link:<br />
                            <a href="https://drive.google.com/file/d/1q4zcMNuZxJoQuw66Dk-iLk3RGtpPGJFw" target="_blank" rel="noopener noreferrer" class="text-blue font-bold shadow-lg">
                                https://drive.google.com/file/d/1q4zcMNuZxJoQuw66Dk-iLk3RGtpPGJFw
                            </a>
                        </p>
                    </section>

                    <!-- DYNAMIC STOCHASTIC SYNTHESIS -->
                    <section>
                        <h4 class="font-bold mb-2">DYNAMIC STOCHASTIC SYNTHESIS</h4>
                        <p class="mb-3">
                            Algorithmic composition code / C++ sound engine | 2022
                        </p>
                        <p class="mb-3">
                            This library reimplements Xenakis and Sergio Luque's dynamic stochastic synthesis algorithm in C++ using openFrameworks. Combined with my formants-detection tool, this system recognizes vowels and extends them algorithmically, creating a method for exploring phonetic diversity through computational means. The project will be used in my upcoming exhibition at the Humboldt-Forum, demonstrating the practical application of my research in linguistic sonification.
                        </p>
                    </section>

                    <!-- PATTERNS FOR C++ -->
                    <section>
                        <h4 class="font-bold mb-2">PATTERNS FOR C++</h4>
                        <p class="mb-3">
                            Threaded pattern synthesis library (C++) | Continuous development | 2024
                        </p>
                        <p class="mb-3">
                            I have been writing multi-threaded classes for C++ to mimic Patterns UGens from SuperCollider. As of now, calling (threaded) libraries with either user-defined functions/lambdas for patterns or using any of the member pattern functions have been implemented.
                        </p>
                        <p class="mb-3">
                            Threaded patterns:<br />
                            <a href="https://drive.google.com/file/d/1E2ptHYe2DnNCncTwB-Xw2yHH-KCmNpXz" target="_blank" rel="noopener noreferrer" class="text-blue font-bold shadow-lg">
                                https://drive.google.com/file/d/1E2ptHYe2DnNCncTwB-Xw2yHH-KCmNpXz
                            </a>
                        </p>
                    </section>

                    <!-- TRACKING COLLECTION -->
                    <section>
                        <h4 class="font-bold mb-2">TRACKING COLLECTION</h4>
                        <p class="mb-3">
                            Gesture-tracking research code (C++, Kinect / POCO Threads) | 2023
                        </p>
                        <p class="mb-3">
                            Below is a list of C++ projects (eventually turned into classes) I am writing as part of my gesture-tracking library for my Second year sonology project at the Institute of Sonology. One of the libraries shows how I create new parametric relationships from Kinect data (example: The rotation of the knee with the speed of hand movement to form a single vector). Another library shows using derivatives and statistical information from mouse movement to form new animations on screen. It also has a first draft of a granular synthesis (credit Aaron Anderson) to be used in my upcoming performance with a dancer at the WaveField Synthesis festival. This is the primary basis library for the gesture recognition phase of the work.
                        </p>
                        <p class="mb-3">
                            Gesture derivatives:<br />
                            <a href="https://drive.google.com/file/d/12MRekXJbVFOT4LYniq2w0cPhMErhMKm1" target="_blank" rel="noopener noreferrer" class="text-blue font-bold shadow-lg">
                                https://drive.google.com/file/d/12MRekXJbVFOT4LYniq2w0cPhMErhMKm1
                            </a>
                        </p>
                    </section>

                    <!-- REALTIME PROCESSING SHOWCASE -->
                    <section>
                        <h4 class="font-bold mb-2">REALTIME PROCESSING SHOWCASE (NL)</h4>
                        <p class="mb-3">
                            Multichannel audiovisual improvisation (24-channel audio + real-time processing sensor data) | The Hague, NL | 2023
                        </p>
                        <p class="mb-3">
                            Experimental presentation exploring the relationship between motion, data, and sound in multi-channel setups using the PinePhone Pro (Linux open source bio Phone). The showcase featured algorithmically triggered visual and sonic elements derived from dancer gesture capture using in-house gesture tracking libraries. The whole sound palette was produced from simple granular synthesis of a sine wave and 1 sample only, where the main transformations are: (1) A sequenced Ring Modulator (2) an FFT freezer, (3) a FFT bin shifter, and (4) a buffer scanner.
                        </p>
                        <p class="mb-3">
                            Listen:<br />
                            <a href="https://drive.google.com/file/d/12MRekXJbVFOT4LYniq2w0cPhMErhMKm1" target="_blank" rel="noopener noreferrer" class="text-blue font-bold shadow-lg">
                                https://drive.google.com/file/d/12MRekXJbVFOT4LYniq2w0cPhMErhMKm1
                            </a>
                        </p>
                    </section>

                    <!-- WORKING WITH ANALOG SYNTH -->
                    <section>
                        <h4 class="font-bold mb-2">WORKING WITH ANALOG SYNTH (DE)</h4>
                        <p class="mb-3">
                            Analog modular synthesis + violin improvisation | 2019
                        </p>
                        <p class="mb-3">
                            My first introduction to synthesizers was through the Berlin DIY community who assembled a comprehensive Eurorack synthesizer setup in Berlin. We started experimenting in 2017 with improvised performance sessions in various underground DIY festivals, culminating with a composition based on "Gagaku" japanese tradition. This piece concentrates on aspects of Gagaku such as its timbral and spectral richness, its openness in rhythm, its minimalism, and chiefly the different tuning systems.
                        </p>
                        <p class="mb-3">
                            Listen:<br />
                            <a href="https://soundcloud.com/grunfeld/impressions-of-gagaku-1" target="_blank" rel="noopener noreferrer" class="text-blue font-bold shadow-lg">
                                https://soundcloud.com/grunfeld/impressions-of-gagaku-1
                            </a>
                        </p>
                    </section>

                    <!-- DEUTSCHE OPER – COMMON SOUND -->
                    <section>
                        <h4 class="font-bold mb-2">DEUTSCHE OPER – COMMON SOUND (DE)</h4>
                        <p class="mb-3">
                            Micro-festival curation / live intermedia performance | Residency 4 weeks | Berlin, DE | 2019
                        </p>
                        <p class="mb-3">
                            Co-Curation of Micro-festival curated and co-produced as part of Common Sound at the Tischlerei, Deutsche Oper Berlin. The laboratory brought together young artists, composers, and performers from diverse backgrounds to experiment across sound, gesture, and stage media, culminating in a series of curated interdisciplinary performances with public workshops.
                        </p>
                        <p class="mb-3">
                            Link:<br />
                            <a href="https://www.youtube.com/watch?v=lfs_h92yqp0" target="_blank" rel="noopener noreferrer" class="text-blue font-bold shadow-lg">
                                https://www.youtube.com/watch?v=lfs_h92yqp0
                            </a>
                        </p>
                    </section>

                    <!-- TRXXXTER – HARMONICA CONCERTO -->
                    <section>
                        <h4 class="font-bold mb-2">TRXXXTER – HARMONICA CONCERTO (DE)</h4>
                        <p class="mb-3">
                            DJ set / radio broadcast with live sampling | 42′15 | Berlin, DE | 2025
                        </p>
                        <p class="mb-3">
                            DJ-set installation and live radio project fusing generative sampling with manipulated harmonica recordings. The performance transformed field textures into cyclical layers through granular processing, creating a hybrid between DJ practice, sound collage, and live coding. Broadcast as part of the Trxxxter Radio Performance Series.
                        </p>
                    </section>

                    <!-- HISTORY SAMPLING USING SHADERS -->
                    <section>
                        <h4 class="font-bold mb-2">HISTORY SAMPLING USING SHADERS</h4>
                        <p class="mb-3">
                            GPU shader image sampler / Interactive visual system | 2024
                        </p>
                        <p class="mb-3">
                            This library collects texture samples either from input video or a collection of images. In this implementation, it uses the distance between mouse position and pixel in shaders to sample different textures coordinated from the supplied Deque of history to interpolate and form new display images. In its next iteration, it will use gestures from LeapMotion instead of mouse positions.
                        </p>
                        <p class="mb-3">
                            Documentation:<br />
                            <a href="https://drive.google.com/file/d/1FlVGGDN7CJEbVuAKrvC_UC0MTw05ZC9L/view?usp=sharing" target="_blank" rel="noopener noreferrer" class="text-blue font-bold shadow-lg">
                                https://drive.google.com/file/d/1FlVGGDN7CJEbVuAKrvC_UC0MTw05ZC9L/view?usp=sharing
                            </a>
                        </p>
                    </section>

                    <!-- OUTFLUX -->
                    <section>
                        <h4 class="font-bold mb-2">OUTFLUX (NL)</h4>
                        <p class="mb-3">
                            Live trio (FFT cross synthesis + violin + phone apps) | 2019
                        </p>
                        <p class="mb-3">
                            A live improvisation trio featured me on violin and electronics, Tristan Beutter on smartphone apps and FFT cross synthesis via Max/MSP and Wacom tablet. The central concept behind the trio is the conceptual and literal exchange of ideas. Sound output from each member is sent to every other member in order to be processed or tweaked live.
                        </p>
                        <p class="mb-3">
                            Listen adblock module:<br />
                            <a href="https://soundcloud.com/grunfeld/adblock-module/s-d45w5" target="_blank" rel="noopener noreferrer" class="text-blue font-bold shadow-lg">
                                https://soundcloud.com/grunfeld/adblock-module/s-d45w5
                            </a>
                        </p>
                    </section>

                    <!-- BERLIN ERRORISTS -->
                    <section>
                        <h4 class="font-bold mb-2">BERLIN ERRORISTS (DE)</h4>
                        <p class="mb-3">
                            Electroacoustic improvisation / Hybrid analog-digital ensemble | 2022
                        </p>
                        <p class="mb-3">
                            An improvisers collective was formed by me in Berlin to create a mix of traditional instruments, everyday objects with contact mics, one analog synthesizer (Eurorack), some programming languages, and manipulated playback of field recordings. The live improvisation consisted of acoustic violin, PureData, vibrating plates, bowed clothes string, a Eurorack synth, and clarinet. The final performance consisted of manipulation of field recordings and samples from the field recording as an impulse response for violin convolution.
                        </p>
                        <p class="mb-3">
                            Listen:<br />
                            <a href="https://drive.google.com/file/d/1Uxy_Kuni0GCXwKlaoPpm9RE0PZNkH5YK/view?usp=sharing" target="_blank" rel="noopener noreferrer" class="text-blue font-bold shadow-lg">
                                https://drive.google.com/file/d/1Uxy_Kuni0GCXwKlaoPpm9RE0PZNkH5YK/view?usp=sharing
                            </a>
                        </p>
                    </section>

                    <!-- SOUND & SPACE WORKSHOP -->
                    <section>
                        <h4 class="font-bold mb-2">SOUND & SPACE WORKSHOP at Curiosity Club (ES)</h4>
                        <p class="mb-3">
                            Workshop | Barcelona | 2025
                        </p>
                        <p class="mb-3">
                            Comprehensive workshop series exploring the materiality and spatiality of sound through multiple sessions at Sound and Music Computing Masters (Curiosity Club: acousmatrix (field recordings and Islamic adhan compositions), sound & space (12-channel dodecaphonic systems), philosophical investigations of sound's nature, n-channel reverb implementations, microphone techniques (coincident and spaced pairs), hybrid spatial approaches combining Chladni figures and Harry Partch's tuning systems, and Japanese concepts of onkyō (sound + resonance).
                        </p>
                        <p class="mb-3">
                            Material:<br />
                            <a href="https://drive.google.com/file/d/1vGRY1WvET-BQ5aUWXFRIiF_Gnoe2gxvC/view?usp=sharing" target="_blank" rel="noopener noreferrer" class="text-blue font-bold shadow-lg">
                                https://drive.google.com/file/d/1vGRY1WvET-BQ5aUWXFRIiF_Gnoe2gxvC/view?usp=sharing
                            </a>
                        </p>
                    </section>

                    <!-- STOCHASTIC TENDENCIES -->
                    <section>
                        <h4 class="font-bold mb-2">STOCHASTIC TENDENCIES</h4>
                        <p class="mb-3">
                            Analogue studio generative composition (Institute of Sonology) | 2021
                        </p>
                        <p class="mb-3">
                            The principal concept behind this composition is Tendency Masks. Tendency mask is a method of containing, enveloping, or masking stochastic processes or events into organized tendencies. Each of these parameters has an element of chance. Pitch/frequency is generated by binary scaling white noise in 8 division bands, the sum of which modulates the frequency of a function generator. The random texture is created by multiplying the function generator output with a controlled random pulse generator. The phrasing is generated by four random envelope generators, summed using a mixing amplifier, the levels on the mixing amplifier determining a variety of phrases. Developed in the analogue studio that continues the tradition of the former Philips electronic music studio.
                        </p>
                        <p class="mb-3">
                            Listen:<br />
                            <a href="https://drive.google.com/file/d/1CgmbqdDxICZjfjskqgHLoF4SJi_pC4P6" target="_blank" rel="noopener noreferrer" class="text-blue font-bold shadow-lg">
                                https://drive.google.com/file/d/1CgmbqdDxICZjfjskqgHLoF4SJi_pC4P6
                            </a>
                        </p>
                    </section>

                    <!-- CATEGORICAL PERCEPTION OF MICROTONALITY -->
                    <section>
                        <h4 class="font-bold mb-2">CATEGORICAL PERCEPTION OF MICROTONALITY (DE)</h4>
                        <p class="mb-3">
                            Research paper / Psychoacoustics study | 2018
                        </p>
                        <p class="mb-3">
                            There are four main components to this research study: Survey of historical approaches to microtonality from multiple traditions. Experimental investigation of tone perception across diverse backgrounds. Creation of an empirical study of categorical boundaries in microtonal discrimination. This project investigates the perception of microtonal intervals in music, examining both historical approaches and contemporary applications.
                        </p>
                        <p class="mb-3">
                            Research paper:<br />
                            <a href="https://drive.google.com/file/d/1oCCvuNM_dlYrX42v_MkD9c2fg3nHulHV" target="_blank" rel="noopener noreferrer" class="text-blue font-bold shadow-lg">
                                https://drive.google.com/file/d/1oCCvuNM_dlYrX42v_MkD9c2fg3nHulHV
                            </a>
                        </p>
                    </section>

                    <!-- UNERHÖRT -->
                    <section>
                        <h4 class="font-bold mb-2">UNERHÖRT (TBA)</h4>
                        <p class="mb-3">
                            4-channel live | 20′ | 2026 | Experiment (Dance) & Fixed Media
                        </p>
                        <p class="mb-3">
                            Machines reflect the desire for control, embodying our expectations of the 'other,' which often results in imbalanced power dynamics centered around ourselves. While we are confined to our own perspectives, could there still be ways to genuinely listen to others? Is there something worth exploring in the potential intersections?
                        </p>
                        <p class="mb-3">
                            I explore several multidisciplinary approaches encompassing sound art, computer software development and improvisational movement. In recent years, the use of AI in creative productions has become increasingly common, raising existential questions about humanity, particularly regarding the possibility of computers outperforming humans. The fear stems from the prioritisation of 'human-like AI' development, which tends to overlook the fundamental differences between humans and machines. In the context of generative AI, its creative output is often evaluated solely through the lens of our aesthetics.
                        </p>
                        <p class="mb-3">
                            In this work I emphasize the dynamics of experimentation and collaboration rather than control in human-machine relationships. Through experiments with contemporary dancers and underground choreographers, it seeks to present an improvisational dialogue between human and machine, exploring the intersection of sound, computation, and dance.
                        </p>
                    </section>

                </div>
            </div>

            <!-- SELECTED PUBLICATIONS -->
            <div class="pb-10 mb-10 border-b-10 border-lavender">
                <h2 class="mb-20 italic">Selected Publications & Presentations</h2>
                <div class="[&_a]:hover:italic space-y-4">
                    <p>Real-time Multi-threaded Facial Movement Analysis for Phonetic Research (forthcoming)</p>
                    <p>Bachelor's Thesis: Wandering the Sounds of Languages, Institute of Sonology (2025)</p>
                    <p>Music History of Microtonality Vol. 1, Self-published (2022)</p>
                    <p>Editorial contribution and proofreading, MusikTexte (2021)</p>
                    <p>Audio Mosaicing & Nonstandard Synthesis Tools Presentation, Petersburg Art Space (2025)</p>
                </div>
            </div>

            <!-- TECHNICAL SKILLS -->
            <div class="pb-10 mb-10 border-b-10 border-blue">
                <h2 class="mb-20 italic">Technical Skills</h2>
                <div class="[&_a]:hover:italic space-y-4">
                    <p><strong>Systems & Programming:</strong> C/C++20/23, Python, Linux (Arch/BSD), MacOS; Git, Docker</p>
                    <p><strong>Music Tech:</strong> SuperCollider, Max/MSP, PureData, CSound; JUCE, Reaper, Ableton Live; Spatial Audio (IEM, WFSCollider); multichannel mixing, Praat, Ardour</p>
                    <p><strong>Graphics:</strong> Vulkan, OpenGL, GLSL/WebGL, OpenCL, Intel TBB, OpenCV</p>
                    <p><strong>Machine Learning:</strong> PyTorch, librosa, HuggingFace Transformers</p>
                    <p><strong>Hardware:</strong> Arduino, OSC/MIDI; Kinect/LeapMotion; KiCad/PCB; Fusion360; 3D printing; CNC</p>
                    <p><strong>Languages:</strong> German, English, Czech</p>
                </div>
            </div>

            <!-- FOOTER / CONTACT -->
            <div class="bg-pink p-10 rounded-2xl text-black antialiased mb-10">
                <div class="md:grid md:grid-cols-2 md:gap-12">
                    <div class="flex flex-col justify-between mb-6 md:mb-0">
                        <h3 class="mb-6 font-swash italic text-5xl">Lydia Krifka-Dobes</h3>
                        <div class="space-y-2">
                            <p><strong>Contact:</strong></p>
                            <p>
                                <a href="mailto:lydiakrifka@gmail.com" class="hover:italic">lydiakrifka@gmail.com</a>
                            </p>
                            <p>+49 1709892923</p>
                            <p>Anna-Louisa-Karsch Str. 3<br />Berlin, 10178, Germany</p>
                        </div>
                    </div>
                    <div class="flex flex-col justify-between">
                        <div class="space-y-2">
                            <p><strong>Links:</strong></p>
                            <p>
                                <a href="https://lydiakrifka.github.io/" target="_blank" rel="noopener noreferrer" class="hover:italic">Personal Website</a>
                            </p>
                            <p>
                                <a href="https://soundcloud.com/grunfeld" target="_blank" rel="noopener noreferrer" class="hover:italic">Soundcloud</a>
                            </p>
                            <p>
                                <a href="https://www.instagram.com/lydia.krifkadobes" target="_blank" rel="noopener noreferrer" class="hover:italic">Instagram</a>
                            </p>
                        </div>
                    </div>
                </div>
            </div>

        </div>
    </main>
</body>
</html>
